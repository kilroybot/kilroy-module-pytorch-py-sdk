{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"kilroy-module-pytorch-py-sdk \ud83d\udd17 SDK for kilroy modules using PyTorch \ud83e\uddf0 Installing \ud83d\udd17 Using pip : pip install kilroy-module-pytorch-py-sdk Usage \ud83d\udd17 from pathlib import Path from kilroy_module_pytorch_py_sdk import PytorchModule , ModuleService , ModuleServer class MyModule ( PytorchModule ): ... # Implement all necessary methods here module = await MyModule . build () service = ModuleService ( module , Path ( \"path/to/state/directory\" )) server = ModuleServer ( service ) await server . run ( host = \"0.0.0.0\" , port = 11000 )","title":"Home"},{"location":"#kilroy-module-pytorch-py-sdk","text":"SDK for kilroy modules using PyTorch \ud83e\uddf0","title":"kilroy-module-pytorch-py-sdk"},{"location":"#installing","text":"Using pip : pip install kilroy-module-pytorch-py-sdk","title":"Installing"},{"location":"#usage","text":"from pathlib import Path from kilroy_module_pytorch_py_sdk import PytorchModule , ModuleService , ModuleServer class MyModule ( PytorchModule ): ... # Implement all necessary methods here module = await MyModule . build () service = ModuleService ( module , Path ( \"path/to/state/directory\" )) server = ModuleServer ( service ) await server . run ( host = \"0.0.0.0\" , port = 11000 )","title":"Usage"},{"location":"usage/","text":"Usage \ud83d\udd17 You can use this package to easily create a module server that uses PyTorch models and complies with the kilroy module API. The easiest way to do this is to create a class that inherits from specific module class and implement all the necessary methods. All methods are either simple coroutines or async generators. Here is an example: from pathlib import Path from kilroy_module_pytorch_py_sdk import PytorchModule , ModuleService , ModuleServer class MyModule ( PytorchModule ): ... # Implement all necessary methods here module = await MyModule . build () service = ModuleService ( module , Path ( \"path/to/state/directory\" )) server = ModuleServer ( service ) await server . run ( host = \"0.0.0.0\" , port = 11000 )","title":"Usage"},{"location":"usage/#usage","text":"You can use this package to easily create a module server that uses PyTorch models and complies with the kilroy module API. The easiest way to do this is to create a class that inherits from specific module class and implement all the necessary methods. All methods are either simple coroutines or async generators. Here is an example: from pathlib import Path from kilroy_module_pytorch_py_sdk import PytorchModule , ModuleService , ModuleServer class MyModule ( PytorchModule ): ... # Implement all necessary methods here module = await MyModule . build () service = ModuleService ( module , Path ( \"path/to/state/directory\" )) server = ModuleServer ( service ) await server . run ( host = \"0.0.0.0\" , port = 11000 )","title":"Usage"},{"location":"features/generator/","text":"Generator \ud83d\udd17 Language model only predicts the probability of the next word. You still need some other logic to generate a whole sentence (or even more). This is where the generator comes in. Generator takes a language model and is responsible for generating complete results. It's optimized for batch processing, so you can generate multiple results at once. You can configure what are the starting sequences (a.k.a. contexts). During generation, contexts are randomly picked from the list. Generator is also able to perform basic cleaning of the results, based on regular expressions. For example, you can remove incomplete sentences at the end of the results.","title":"Generator"},{"location":"features/generator/#generator","text":"Language model only predicts the probability of the next word. You still need some other logic to generate a whole sentence (or even more). This is where the generator comes in. Generator takes a language model and is responsible for generating complete results. It's optimized for batch processing, so you can generate multiple results at once. You can configure what are the starting sequences (a.k.a. contexts). During generation, contexts are randomly picked from the list. Generator is also able to perform basic cleaning of the results, based on regular expressions. For example, you can remove incomplete sentences at the end of the results.","title":"Generator"},{"location":"features/optimizers/","text":"Optimizers \ud83d\udd17 Optimizers are wrappers around PyTorch optimizers. They are used to update the parameters of a model during training. Optimizers implemented by default: AdamOptimizer RMSPropOptimizer SGDOptimizer You can change the parameters at runtime.","title":"Optimizers"},{"location":"features/optimizers/#optimizers","text":"Optimizers are wrappers around PyTorch optimizers. They are used to update the parameters of a model during training. Optimizers implemented by default: AdamOptimizer RMSPropOptimizer SGDOptimizer You can change the parameters at runtime.","title":"Optimizers"},{"location":"features/schedulers/","text":"Schedulers \ud83d\udd17 Schedulers are wrappers around PyTorch learning rate schedulers. They are used to update the learning rate of an optimizer during training. Schedulers implemented by default: ConstantScheduler CosineAnnealingScheduler CyclicScheduler ExponentialScheduler LinearScheduler MultiStepScheduler OneCycleScheduler ReduceOnPlateauScheduler StepScheduler WarmRestartsScheduler You can change the parameters at runtime.","title":"Schedulers"},{"location":"features/schedulers/#schedulers","text":"Schedulers are wrappers around PyTorch learning rate schedulers. They are used to update the learning rate of an optimizer during training. Schedulers implemented by default: ConstantScheduler CosineAnnealingScheduler CyclicScheduler ExponentialScheduler LinearScheduler MultiStepScheduler OneCycleScheduler ReduceOnPlateauScheduler StepScheduler WarmRestartsScheduler You can change the parameters at runtime.","title":"Schedulers"},{"location":"features/trainers/","text":"Trainers \ud83d\udd17 Trainers define how to train a model (or multiple models). They are given data and are responsible for fitting the model to the data, including when to stop training. All implemented trainers are listed below. VanillaTrainer \ud83d\udd17 This trainer simply uses a single model and optimizes it directly. It's straightforward and stable, but it might take a long time to train. But it's a good starting point. ActorCriticTrainer \ud83d\udd17 This module uses two models: an actor and a critic. The actor is the main model that is used for generating results. The critic is used to evaluate the actor's results. The critic can be useful for two reasons: For variance reduction. An ideal critic is able to predict average future reward. You can subtract the predicted value from the actual reward to bring the values closer to zero. For bootstrapping. As the critic is able to evaluate the actor's results at any point, you can use it to evaluate generated results without having to actually post them. This way we are maximizing the reward as given by the critic, but these rewards should be a good approximation of the actual rewards. This trainer is more complicated and less stable than the vanilla trainer, but it combats the problem of sample inefficiency and big variance.","title":"Trainers"},{"location":"features/trainers/#trainers","text":"Trainers define how to train a model (or multiple models). They are given data and are responsible for fitting the model to the data, including when to stop training. All implemented trainers are listed below.","title":"Trainers"},{"location":"features/trainers/#vanillatrainer","text":"This trainer simply uses a single model and optimizes it directly. It's straightforward and stable, but it might take a long time to train. But it's a good starting point.","title":"VanillaTrainer"},{"location":"features/trainers/#actorcritictrainer","text":"This module uses two models: an actor and a critic. The actor is the main model that is used for generating results. The critic is used to evaluate the actor's results. The critic can be useful for two reasons: For variance reduction. An ideal critic is able to predict average future reward. You can subtract the predicted value from the actual reward to bring the values closer to zero. For bootstrapping. As the critic is able to evaluate the actor's results at any point, you can use it to evaluate generated results without having to actually post them. This way we are maximizing the reward as given by the critic, but these rewards should be a good approximation of the actual rewards. This trainer is more complicated and less stable than the vanilla trainer, but it combats the problem of sample inefficiency and big variance.","title":"ActorCriticTrainer"}]}